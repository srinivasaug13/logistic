{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb063e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b837d574",
   "metadata": {},
   "source": [
    "Import libraries and read the dataset.\n",
    "\n",
    "Do the needful Exploratory Data Analysis.\n",
    "\n",
    "State your insights.\n",
    "\n",
    "Build a linear regression model to predict the house prices\n",
    "\n",
    "Try to find out important features or create new features to improve the performance for your model.\n",
    "\n",
    "Use appropriate cross validations techniques to find out the best predictor parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee1342c",
   "metadata": {},
   "source": [
    "Overview\n",
    "1.Read the problem statement.\n",
    "\n",
    "2.Get the dataset.\n",
    "\n",
    "3.Explore the dataset.\n",
    "\n",
    "4.Pre-processing of dataset.\n",
    "\n",
    "5.Visualization\n",
    "\n",
    "6.Transform the dataset for building machine learning model.\n",
    "\n",
    "7.Split data into train, test set.\n",
    "\n",
    "7.Build Model.\n",
    "\n",
    "8.Apply the model.\n",
    "\n",
    "9.Evaluate the model.\n",
    "\n",
    "10.Finding Optimal K value\n",
    "\n",
    "11.Repeat 7,8,9 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b424d6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import ExtraTreesRegressor,GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets try out some more trees and ensemble methods for a better understanding of the feature importances\n",
    "\n",
    "# the models we will run\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# some metrics to help us out\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ee7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788c7002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d810b56f",
   "metadata": {},
   "source": [
    "# import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f5fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1215db",
   "metadata": {},
   "source": [
    "# Data exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c493d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.info()\n",
    "df.dtypes\n",
    "df.describe().transpose()\n",
    "df.describe(include='all').transpose()\n",
    "as we can see the data contains 21 columns such as date, price, floors ...etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f41f55c",
   "metadata": {},
   "source": [
    "# hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c762aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstat,p = stats.ttest_rel(ds['New Scheme (in thousands)'],ds['Old Scheme (in thousands)'],axis = 0)\n",
    "print(tstat)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81176492",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(ds) #this is the sample size \n",
    "df = N-1\n",
    "pvalue = 1-(stats.t.cdf(tstat,df))\n",
    "print(pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f48d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_1samp(ds1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b978a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_stat = (x_bar - 5000)/ stderror\n",
    "t_stat\n",
    "power_of_test = stats.t.sf((t_stat),n-1)\n",
    "power_of_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef45c783",
   "metadata": {},
   "source": [
    "# missing value Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d5c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see if we have any missing value or null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd81f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "print(df.isnull().any())\n",
    "print(df.isnull().sum())\n",
    "sns.heatmap(df.isnull(), cbar=False)\n",
    "msno.heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing Value Imputation for Occupation\n",
    "ctab = pd.crosstab(LR_DF[\"Occupation\"].fillna(''),LR_DF[\"Target\"] )\n",
    "ctab['RRate'] = ctab[1] *100 / (ctab[1] + ctab[0])\n",
    "ctab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dde679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_DF[\"HP_Imputed\"]=LR_DF[\"Holding_Period\"].fillna(18)\n",
    "LR_DF[\"HP_Imputed\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddff74",
   "metadata": {},
   "source": [
    "# data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc404ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Bank_DF[\"Age\"],bins = \"auto\")\n",
    "\n",
    "sns.pairplot(data=df, hue =\"Personal Loan\", diag_kind= \"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216940c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = 'Age', data = Bank_DF)\n",
    "\n",
    "plt.figure(figsize=(100,5))\n",
    "sns.barplot(x='Income', y='Personal Loan',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a712c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(housing[['sqft_lot','sqft_above','price','sqft_living','bedrooms']], \n",
    "                 hue='bedrooms', palette='tab20',size=6)\n",
    "g.set(xticklabels=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d0f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(tips['day'], tips['total_bill'])\n",
    "sns.countplot(tips['day'], hue = tips['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab1fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "housing.hist(bins=10, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f409de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualization  using box plot###\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.boxplot(data=Master_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208b94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Master_data[\"lat\"], bins = \"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1bd035",
   "metadata": {},
   "source": [
    "# drop sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7300dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop Customer ID, Target Variables\n",
    "train_pv = train.drop(labels = [\"Cust_ID\", \"Target\"], axis = 1)\n",
    "train_pv.head()\n",
    "\n",
    "df= df.drop(labels = [\"ID\"], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4697f51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11908aeb",
   "metadata": {},
   "source": [
    "# Create the dummies for the categorical variables/features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcbda05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = insurance_reg.iloc[:, :-1].values\n",
    "y = insurance_reg.iloc[:, 6].values\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X.fit_transform(X[:, 1])\n",
    "X[:, 4] = labelencoder_X.fit_transform(X[:, 4])\n",
    "X[:, 5] = labelencoder_X.fit_transform(X[:, 5])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [5])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa8fcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "661d9ae0",
   "metadata": {},
   "source": [
    "# variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Information Value\n",
    "exec(open(\"F:/ML&AI/Supervised Learning/Logistic_Regression/Python/Logistic_Regression/iv_function.py\").read())\n",
    "iv = information_value(df = LR_DF.iloc[:,1:],target = LR_DF.Target)\n",
    "iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ecc2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting the IV\n",
    "index = np.arange(len(iv.VAR_NAME))\n",
    "def plot_bar_x():\n",
    "    # this is for plotting purpose\n",
    "    index = np.arange(len(iv.VAR_NAME))\n",
    "    plt.bar(index, iv.IV)\n",
    "    plt.xlabel('Var', fontsize=5)\n",
    "    plt.ylabel('IV', fontsize=5)\n",
    "    plt.xticks(index, iv.VAR_NAME, fontsize=5, rotation=30)\n",
    "    plt.title('IV Plot')\n",
    "    plt.show()\n",
    "\n",
    "plot_bar_x()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a5c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Information Value\n",
    "exec(open(\"D:/K2Analytics/Python/Logistic_Regression/iv_function.py\").read())\n",
    "iv = information_value(df = LR_DF.iloc[:,1:],target = LR_DF.Target)\n",
    "iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a016543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a7b117d",
   "metadata": {},
   "source": [
    "# Capping and Flooring outlier#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0accc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Outlier Function\n",
    "def outlier_treatment(df, col_name):\n",
    "    df = df.copy()\n",
    "    x = df[col_name]\n",
    "    median, std = x.median(), x.std()\n",
    "    upper_outlier_value = median + 2 * std\n",
    "    lower_outlier_value = median - 2 * std\n",
    "\n",
    "    upper_outlier_row_index = (x - median) > 2 * std\n",
    "    lower_outlier_row_index = (median - x) > 2 * std\n",
    "\n",
    "    x[upper_outlier_row_index] = upper_outlier_value\n",
    "    x[lower_outlier_row_index] = lower_outlier_value\n",
    "    return x\n",
    "\n",
    "LR_DF[\"Bal_cap\"] = outlier_treatment(df = LR_DF, col_name = \"Balance\")\n",
    " \n",
    "\n",
    "\n",
    "#LR_DF[\"Bal_cap\"]=LR_DF[\"Balance\"].map(lambda x: 560000 if x>560000 else x)\n",
    "\n",
    "LR_DF[\"Bal_cap\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b8c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Remove the outliers from the data\n",
    "#del df[\"market leading airline\"]\n",
    "#df1 = df\n",
    "df1.head(20)\n",
    "Q1 = df1.quantile(0.25)\n",
    "Q3 = df1.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df1_out = df1[~((df1 < (Q1 - 1.5 * IQR)) |(df1 > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "df1_out.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20076b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb34b9cc",
   "metadata": {},
   "source": [
    "# corrilation , correlation coefficient ranges from â€“1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_reg.corr()\n",
    "sns.heatmap(insurance_reg.corr(), annot=True, vmin=-1, vmax=1, cmap='seismic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1012e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation Output\n",
    "sns.heatmap(inc_exp.corr(), annot=True, vmin=-1, vmax=1, cmap='seismic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e49a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "corr = housing.corr()\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc424d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transforming Age Variable\n",
    "LR_DF[\"DV_Age\"]=LR_DF[\"Age\"].map(lambda\n",
    "         x: 43-(x-43) if x>43 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537903b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9f4a00e",
   "metadata": {},
   "source": [
    "# scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4669e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data with the label\n",
    "scaler = preprocessing.StandardScaler().fit(housing_scaled)\n",
    "new_df = scaler.transform(housing_scaled)\n",
    "housing_scaled = pd.DataFrame(data=new_df, index=list(range(len(new_df))), columns=housing_scaled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bcacaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a128dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scaling all variables\n",
    "train_z_trf = train_pv.apply(zscore)\n",
    "train_z_trf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce7334",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store the normalized features data into np array\n",
    "X_train = np.array(train_z_trf)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3609848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6fe530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0556648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0a745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) \n",
    "#split the data with raito 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing_scaled.values, housing_labels.values, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88973a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980877f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before scaling the data I'm going to deop price col since it is a label then droping date and id since does't make any\n",
    "housing_scaled = housing.drop('price', axis=1)  # drop labels for training set\n",
    "housing_scaled = housing_scaled.drop('date', axis=1)  # drop date  for training set\n",
    "housing_scaled = housing_scaled.drop('id', axis=1)  # drop id  for training set\n",
    "\n",
    "#extract the labels\n",
    "housing_labels = housing['price'].copy()\n",
    "#scale the data with the label\n",
    "scaler = preprocessing.StandardScaler().fit(housing_scaled)\n",
    "new_df = scaler.transform(housing_scaled)\n",
    "housing_scaled = pd.DataFrame(data=new_df, index=list(range(len(new_df))), columns=housing_scaled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a0e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b4d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e35850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VIF Factor\n",
    "def VIF(formula,data):\n",
    "    from patsy import dmatrices\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    y , X = dmatrices(formula,data = data,return_type=\"dataframe\")\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"Variable\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) \n",
    "        for i in range(X.shape[1])]\n",
    "    return(vif.round(1))\n",
    "\n",
    "vif=VIF(\"\"\"Target ~ DV_Age + SCR + Bal_cap \n",
    "        + No_OF_CR_TXNS + occ_recat + HP_Imputed\"\"\",mydata_dev)\n",
    "vif     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2582f8b",
   "metadata": {},
   "source": [
    "# Transforming Age Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transforming Age Variable\n",
    "LR_DF[\"DV_Age\"]=LR_DF[\"Age\"].map(lambda\n",
    "         x: 43-(x-43) if x>43 else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b6690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets try out some more trees and ensemble methods for a better understanding of the feature importances\n",
    "\n",
    "# the models we will run\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# some metrics to help us out\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1219e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = {}\n",
    "# Create our function which stores the feature rankings to the ranks dictionary\n",
    "def ranking(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x,2), ranks)\n",
    "    return dict(zip(names, ranks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bab752",
   "metadata": {},
   "source": [
    "# Variance Inflation Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba17e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variance Inflation Factor (VIF) for Multi-Collinearity Check\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def VIF(formula,data):\n",
    "    y , X = dmatrices(formula,data = data,return_type=\"dataframe\")\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"Var_Name\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) \\\n",
    "       for i in range(X.shape[1])]\n",
    "    return(vif.round(1))\n",
    "\n",
    "vif_check =VIF(\"Mthly_HH_Expense ~ Mthly_HH_Income+\\\n",
    "        No_of_Fly_Members+ Emi_or_Rent_Amt+\\\n",
    "        Annual_HH_Income\" ,data = inc_exp)\n",
    "vif_check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7fd9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b7224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VIF Factor\n",
    "def VIF(formula,data):\n",
    "    from patsy import dmatrices\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    y , X = dmatrices(formula,data = data,return_type=\"dataframe\")\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"Variable\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) \n",
    "        for i in range(X.shape[1])]\n",
    "    return(vif.round(1))\n",
    "\n",
    "vif=VIF(\"\"\"Target ~ DV_Age + SCR + Bal_cap \n",
    "        + No_OF_CR_TXNS + occ_recat + HP_Imputed\"\"\",mydata_dev)\n",
    "vif     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c862fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cdae3b1",
   "metadata": {},
   "source": [
    "# Target Variable Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b401b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Personal Loan\"]).count()\n",
    "\n",
    "## Target Variable Frequency Distribution\n",
    "freq = dev['Target'].value_counts().to_frame()\n",
    "freq.reset_index(inplace=True)\n",
    "freq.columns = [freq.columns[1], 'count']\n",
    "freq['prop'] = freq['count'] / sum(freq['count'])\n",
    "freq\n",
    "\n",
    "import seaborn as sns\n",
    "sns.countplot(Bank_DF['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacab296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96ea9aba",
   "metadata": {},
   "source": [
    "# Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84548034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51843165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f25ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model development\n",
    "#spliting into development, validation and hold-out sample\n",
    "mydata = LR_DF.copy()\n",
    "mydata_dev, mydata_val, mydata_holdout = np.split(\n",
    "        mydata.sample(frac=1, random_state=1212), \n",
    "        [int(.5*len(mydata)), \n",
    "         int(.8*len(mydata))]\n",
    "        )\n",
    "\n",
    "(len(mydata_dev), len(mydata_val), len(mydata_holdout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e6b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into training and test set in 70:30 ratio\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fd31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e08e1",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d6f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple Linear Regression Model\n",
    "import statsmodels.formula.api as sm\n",
    "linear_mod = sm.ols(formula =\"Mthly_HH_Expense ~ Mthly_HH_Income\" , \n",
    "                    data = inc_exp).fit()\n",
    "\n",
    "#Get the model summary\n",
    "linear_mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1986dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiple Linear Regression\n",
    "m_linear_mod = sm.ols(formula =\"Mthly_HH_Expense ~ Mthly_HH_Income+\\\n",
    "                      No_of_Fly_Members+ Emi_or_Rent_Amt+\\\n",
    "                      Annual_HH_Income\" ,data = inc_exp).fit()\n",
    "\n",
    "m_linear_mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa178c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "model = sm.OLS(y_train,X_train)\n",
    "fitted1 =model.fit()\n",
    "fitted1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e3156",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fitted1.predict(X_test)\n",
    "y_pred\n",
    "RSS = ((y_test-y_pred)**2).sum()\n",
    "import numpy as np\n",
    "MSE = np.mean((y_test-y_pred)**2).sum()\n",
    "RMSE = np.sqrt(MSE)\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adafdcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "colnames = housing_scaled.columns\n",
    "\n",
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(X_train,y_train)\n",
    "rfe = RFE(lr, n_features_to_select=1, verbose =3 )\n",
    "rfe.fit(X_train,y_train)\n",
    "ranks[\"RFE\"] = ranking(list(map(float, rfe.ranking_)), colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f56e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similarly It can be done with randomforestregressor model\n",
    "rf = RandomForestRegressor(n_jobs=-1, n_estimators=50, verbose=3)\n",
    "rf.fit(X_train,y_train)\n",
    "ranks[\"RF\"] = ranking(rf.feature_importances_, colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55646aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = DecisionTreeRegressor()\n",
    "dr.fit(X_train,y_train)\n",
    "drimp = dr.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=100)\n",
    "rfr.fit(X_train,y_train)\n",
    "rfrimp = rfr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aade7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr =  GradientBoostingRegressor(n_estimators=100)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbrimp = gbr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45891290",
   "metadata": {},
   "outputs": [],
   "source": [
    "abr =  AdaBoostRegressor(n_estimators=100)\n",
    "abr.fit(X_train,y_train)\n",
    "abrimp = abr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522ccbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestRegressor with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5647b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid=[\n",
    "{'n_estimators':[3,10,30,40,50],\t'max_features':[10,14,18]},\n",
    "{'n_estimators':[3,10],'max_features':[14,18]}]\n",
    "forest_reg=RandomForestRegressor(random_state=0,n_jobs=-1)\n",
    "rnd_grid_search=GridSearchCV(forest_reg,param_grid,cv=5)\n",
    "rnd_grid_search.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e0ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_grid_search.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe92c3f",
   "metadata": {},
   "source": [
    "# Create a regularized RIDGE model and note the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c554a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=.3)\n",
    "ridge.fit(X_train,y_train)\n",
    "print (\"Ridge model:\", (ridge.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf91c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ridge.score(X_train, y_train))\n",
    "print(ridge.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c969e",
   "metadata": {},
   "source": [
    "# Create a regularized LASSO model and note the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0288f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train,y_train)\n",
    "print (\"Lasso model:\", (lasso.coef_))\n",
    "\n",
    "# Observe, many of the coefficients have become 0 indicating drop of those dimensions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d49397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lasso.score(X_train, y_train))\n",
    "print(lasso.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1bd4ff",
   "metadata": {},
   "source": [
    "# logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c1b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required Packages\n",
    "import statsmodels.formula.api as sm\n",
    "import statsmodels.api\n",
    "## Running one variable Logistic Regression\n",
    "mylogit = sm.glm(formula = \"Target~ Age\" , data = mydata_dev,\n",
    "                    family=statsmodels.api.families.Binomial()).fit()\n",
    "mylogit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc56fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running regression with all the variables\n",
    "mylogit = sm.glm(formula = \"\"\"Target~ DV_Age + Gender + SCR + Bal_cap \n",
    "        + No_OF_CR_TXNS + Occu_Imputed + HP_Imputed\"\"\" , \n",
    "        data = mydata_dev, family=statsmodels.api.families.Binomial()).fit()\n",
    "mylogit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3f4aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model_score = model.score(X_test, y_test)\n",
    "y_predict = model.predict(X_test)\n",
    "print(model_score)\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d5dfd",
   "metadata": {},
   "source": [
    "# K Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062bb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using Cross Validation\n",
    "from sklearn import model_selection\n",
    "seed = 1\n",
    "#kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "kfold = model_selection.KFold(n_splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6161f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75ecf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_selection.cross_val_score(model, X_train, y_train, scoring='r2', cv=kfold)\n",
    "\n",
    "\n",
    "print(\"Cross Validation Test R Squared  \"  )\n",
    "print((results[0:2]))\n",
    "print(\"*****************\")\n",
    "print(\"R Squared: %.3f \" % (results.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d511358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test R^2\n",
    "model.fit( X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dea1c1",
   "metadata": {},
   "source": [
    "# #KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9f6c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "k_range = list(range(1, 31))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00fa7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train,y_train)\n",
    "# examine the first result\n",
    "print(grid.cv_results_['params'][0])\n",
    "print(grid.cv_results_['mean_test_score'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2718f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "plt.plot(k_range, grid_mean_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630bf820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85d0813",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
    "           weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699dc855",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e4fd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda22cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion)\n",
    "#[row, column]\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf81776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy calculation\n",
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "## classification error\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "print(classification_error)\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3413b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = TP / float(FN + TP)\n",
    "\n",
    "print(sensitivity)\n",
    "print(metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(specificity)\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "\n",
    "print(precision)\n",
    "print(metrics.precision_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80412fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate = FP / float(TN + FP)\n",
    "print(false_positive_rate)\n",
    "print(1 - specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='Knn')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('Knn(n_neighbors=3) ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b910eb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4697b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Area under ROC curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test,y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cross-validated AUC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(KNN, X_train, y_train, cv=10, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ceecd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf7b451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2f27e4e",
   "metadata": {},
   "source": [
    "# GridSearchCV helps Parameter Tuning and Optimize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17b86c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dedae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "k = np.arange(151,163,2)\n",
    "knn = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors' : k, 'algorithm' : ['kd_tree']}\n",
    "#parameters = {'n_neighbors' : k, 'algorithm' : ['kd_tree', 'ball_tree']}\n",
    "GS = GridSearchCV(knn, parameters, scoring = 'roc_auc', cv=3, verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f4b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "GS.best_params_\n",
    "GS.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5847ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hold Out Model Performance - AUC\n",
    "hold_out['prob'] = pd.DataFrame(GS.predict_proba(X_test))[1]\n",
    "h_auc = roc_auc_score(hold_out[\"Target\"],hold_out[\"prob\"])\n",
    "h_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc7340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c49c6744",
   "metadata": {},
   "source": [
    "# RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6300da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "k = np.arange(51,201,2)\n",
    "knn = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors' : k, 'algorithm' : ['kd_tree', 'ball_tree']}\n",
    "RS = RandomizedSearchCV(knn, parameters, n_iter=10, scoring = 'roc_auc', cv=3, verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d07a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "RS.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e67a6a",
   "metadata": {},
   "source": [
    "# model perfformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecaa62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Roc_Curve and KS\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(mydata_dev[\"Target\"],mydata_dev[\"prob\"] )\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "KS = (tpr - fpr).max()\n",
    "KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2717a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(mydata_dev[\"Target\"],mydata_dev[\"prob\"])\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9666a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83980ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix and Classification Accuracy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score   \n",
    "confusion_matrix = (\n",
    "    {\"conf_matx\": confusion_matrix(mydata_dev.Target,mydata_dev[\"class\"]),\n",
    "     \"accuracy\": accuracy_score(mydata_dev.Target,mydata_dev[\"class\"])\n",
    "    })\n",
    "\n",
    "print(\"confusion matrix \\n\" , confusion_matrix[\"conf_matx\"], \n",
    "      \"\\n\\nclassification accuracy \", confusion_matrix[\"accuracy\"]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gini inequality\n",
    "def gini(list_of_values):\n",
    "    sorted_list = sorted(list_of_values)\n",
    "    height, area = 0, 0\n",
    "    for value in sorted_list:\n",
    "        height += value\n",
    "        area += height - value / 2.\n",
    "    fair_area = height * len(list_of_values) / 2.\n",
    "    return (fair_area - area) / fair_area\n",
    "\n",
    "gini_coeff = gini(mydata_dev[\"prob\"])\n",
    "gini_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ff1f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy calculation\n",
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "## classification error\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "print(classification_error)\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aaef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = TP / float(FN + TP)\n",
    "\n",
    "print(sensitivity)\n",
    "print(metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(specificity)\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "\n",
    "print(precision)\n",
    "print(metrics.precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09237e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_1 = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred_class)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e73e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Area under ROC curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test,y_pred_proba_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aaac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cross-validated AUC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(logreg, X_train, y_train, cv=10, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cda1163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084f39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725339b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylogit_val = sm.glm(formula = \"\"\"Target ~ DV_Age + SCR + Bal_cap \n",
    "        + No_OF_CR_TXNS + occ_recat + HP_Imputed\"\"\" , \n",
    "        data = mydata_val, family=statsmodels.api.families.Binomial()).fit()\n",
    "mylogit_val.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b369719",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Development Model Summary\n",
    "mylogit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6edf02b",
   "metadata": {},
   "source": [
    "# naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b45679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "NB = BernoulliNB()\n",
    "NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef19ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for the testing set\n",
    "y_pred_class1 = NB.predict(X_test)\n",
    "\n",
    "# save confusion matrix and slice into four pieces\n",
    "from sklearn import metrics\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class1)\n",
    "print(confusion)\n",
    "#[row, column]\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8158df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "\n",
    "## classification error\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "print(classification_error)\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred_class1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4adcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = TP / float(FN + TP)\n",
    "\n",
    "print(sensitivity)\n",
    "print(metrics.recall_score(y_test, y_pred_class1))\n",
    "\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(specificity)\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "\n",
    "print(precision)\n",
    "print(metrics.precision_score(y_test,y_pred_class1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate = FP / float(TN + FP)\n",
    "print(false_positive_rate)\n",
    "print(1 - specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred_class1)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_2 = NB.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c594b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_2)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='Naive Bayes')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('Naive Bayes ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00420dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Area under ROC curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test,y_pred_proba_2)\n",
    "\n",
    "# calculate cross-validated AUC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(NB, X_train, y_train, cv=10, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8667cba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4727bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a56e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
